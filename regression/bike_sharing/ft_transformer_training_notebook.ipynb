{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FT-Transformer Training for Bike Sharing Regression\n",
    "\n",
    "This notebook demonstrates how to train an FT-Transformer model for bike sharing regression using the modular training functions.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The FT-Transformer (Feature Tokenizer + Transformer) is a state-of-the-art architecture for tabular data that:\n",
    "- Converts features into embeddings using feature tokenization\n",
    "- Uses multi-head attention to capture feature interactions\n",
    "- Applies layer normalization and residual connections\n",
    "- Provides excellent performance on regression tasks\n",
    "\n",
    "## Dataset\n",
    "- **Source**: UCI ML Repository - Bike Sharing Dataset\n",
    "- **Task**: Regression (predicting bike rental count)\n",
    "- **Features**: 16 features (weather, time, seasonal factors)\n",
    "- **Target**: Total bike rental count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ rtdl library imported successfully\n",
      "rtdl version: 0.0.13\n",
      "‚úÖ Enhanced evaluation imported successfully\n",
      "Using device: cuda\n",
      "üö¥ FT-Transformer Training for Bike Sharing Regression\n",
      "Dataset: Bike Sharing Dataset\n"
     ]
    }
   ],
   "source": [
    "# Import all training functions\n",
    "from ft_transformer_training_functions import *\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"üö¥ FT-Transformer Training for Bike Sharing Regression\")\n",
    "print(\"Dataset: Bike Sharing Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Preprocessed Data\n",
    "\n",
    "Load the preprocessed bike sharing data from Section 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading preprocessed bike sharing data...\n",
      "‚úÖ Preprocessed data loaded successfully!\n",
      "Training set: (11122, 13)\n",
      "Validation set: (2781, 13)\n",
      "Test set: (3476, 13)\n",
      "Features: 13\n",
      "Task: Regression (Bike Count Prediction)\n",
      "Target range: [1, 976]\n",
      "\n",
      "Checking for invalid values...\n",
      "NaN in X_train: False\n",
      "Inf in X_train: False\n",
      "NaN in y_train: False\n",
      "X_train min: -3.2513, max: 5.8007\n",
      "y_train min: 1, max: 976\n",
      "\n",
      "üìä Data Summary:\n",
      "   Training samples: 11,122\n",
      "   Validation samples: 2,781\n",
      "   Test samples: 3,476\n",
      "   Features: 13\n",
      "   Target range: [1, 976]\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "(X_train_scaled, X_val_scaled, X_test_scaled, \n",
    " y_train, y_val, y_test, feature_names, data_summary) = load_preprocessed_data('./bike_sharing_preprocessed_data.pkl')\n",
    "\n",
    "print(f\"\\nüìä Data Summary:\")\n",
    "print(f\"   Training samples: {len(X_train_scaled):,}\")\n",
    "print(f\"   Validation samples: {len(X_val_scaled):,}\")\n",
    "print(f\"   Test samples: {len(X_test_scaled):,}\")\n",
    "print(f\"   Features: {len(feature_names)}\")\n",
    "print(f\"   Target range: [{y_train.min():.0f}, {y_train.max():.0f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Training\n",
    "\n",
    "Convert data to PyTorch tensors and create data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "batch_size = 256\n",
    "\n",
    "(train_loader, val_loader, test_loader, feature_info,\n",
    " X_train_tensor, X_val_tensor, X_test_tensor,\n",
    " y_train_tensor, y_val_tensor, y_test_tensor) = prepare_data_for_training(\n",
    "    X_train_scaled, X_val_scaled, X_test_scaled, \n",
    "    y_train, y_val, y_test, feature_names, device, batch_size)\n",
    "\n",
    "print(f\"\\n‚úÖ Data preparation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create FT-Transformer Model\n",
    "\n",
    "Create the FT-Transformer model for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FT-Transformer model\n",
    "model, total_params = create_ft_transformer_model(feature_info, device)\n",
    "\n",
    "print(f\"\\nü§ñ Model created with {total_params:,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setup Training Components\n",
    "\n",
    "Setup loss function, optimizer, and scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training components\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-5\n",
    "\n",
    "criterion, optimizer, scheduler, training_config = setup_training(\n",
    "    model, learning_rate, weight_decay)\n",
    "\n",
    "print(f\"\\nüîß Training setup completed!\")\n",
    "print(f\"   Learning rate: {learning_rate}\")\n",
    "print(f\"   Weight decay: {weight_decay}\")\n",
    "print(f\"   Max epochs: {training_config['n_epochs']}\")\n",
    "print(f\"   Early stopping patience: {training_config['patience']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Model\n",
    "\n",
    "Train the FT-Transformer model with early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model, history, best_epoch, training_time = train_ft_transformer(\n",
    "    model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "    training_config, device)\n",
    "\n",
    "print(f\"\\nüèÅ Training completed in {training_time:.2f} seconds\")\n",
    "print(f\"   Best epoch: {best_epoch + 1}\")\n",
    "print(f\"   Final validation R¬≤: {history['val_r2'][best_epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate the Model\n",
    "\n",
    "Evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "predictions, metrics = evaluate_model(model, X_test_tensor, y_test_tensor, device)\n",
    "\n",
    "print(f\"\\nüìä Test Set Performance:\")\n",
    "print(f\"   R¬≤ Score: {metrics['r2_score']:.4f}\")\n",
    "print(f\"   RMSE: {metrics['rmse']:.4f}\")\n",
    "print(f\"   MAE: {metrics['mae']:.4f}\")\n",
    "print(f\"   MAPE: {metrics['mape']:.2f}%\")\n",
    "print(f\"   Explained Variance: {metrics['explained_variance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Visualizations\n",
    "\n",
    "Create training and evaluation plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training plots\n",
    "create_training_plots(history, best_epoch, './Section2_Model_Training')\n",
    "\n",
    "print(\"\\nüìà Training plots created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation plots\n",
    "create_evaluation_plots(y_test, predictions, './Section2_Model_Training')\n",
    "\n",
    "print(\"\\nüìä Evaluation plots created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results\n",
    "\n",
    "Save all results, model, and generated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "save_results(model, history, metrics, predictions, y_test, feature_names, \n",
    "            training_time, total_params, './Section2_Model_Training')\n",
    "\n",
    "print(\"\\nüíæ All results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Alternative: Run Complete Pipeline\n",
    "\n",
    "Alternatively, you can run the complete pipeline with a single function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run complete pipeline (alternative approach)\n",
    "# Uncomment the following lines to run the complete pipeline in one go:\n",
    "\n",
    "# model, history, metrics, predictions, feature_names = run_complete_ft_transformer_training(\n",
    "#     data_path='./bike_sharing_preprocessed_data.pkl',\n",
    "#     device=device,\n",
    "#     batch_size=256,\n",
    "#     learning_rate=1e-4,\n",
    "#     weight_decay=1e-5,\n",
    "#     save_dir='./Section2_Model_Training'\n",
    "# )\n",
    "\n",
    "print(\"\\nüöÄ Complete pipeline function available for one-step execution!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Analysis and Insights\n",
    "\n",
    "Analyze the trained model performance and provide insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FT-TRANSFORMER PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüéØ Model Performance:\")\n",
    "r2_score = metrics['r2_score']\n",
    "if r2_score > 0.9:\n",
    "    performance_level = \"Excellent\"\n",
    "elif r2_score > 0.8:\n",
    "    performance_level = \"Good\"\n",
    "elif r2_score > 0.7:\n",
    "    performance_level = \"Moderate\"\n",
    "else:\n",
    "    performance_level = \"Needs Improvement\"\n",
    "\n",
    "print(f\"   Performance Level: {performance_level} (R¬≤ = {r2_score:.4f})\")\n",
    "print(f\"   RMSE: {metrics['rmse']:.2f} bikes\")\n",
    "print(f\"   MAE: {metrics['mae']:.2f} bikes\")\n",
    "print(f\"   MAPE: {metrics['mape']:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìä Model Characteristics:\")\n",
    "print(f\"   Total Parameters: {total_params:,}\")\n",
    "print(f\"   Training Time: {training_time:.2f} seconds\")\n",
    "print(f\"   Best Epoch: {best_epoch + 1}\")\n",
    "\n",
    "print(f\"\\nüí° Business Insights:\")\n",
    "avg_actual = y_test.mean()\n",
    "avg_error = metrics['mae']\n",
    "error_percentage = (avg_error / avg_actual) * 100\n",
    "\n",
    "print(f\"   Average bike count: {avg_actual:.0f}\")\n",
    "print(f\"   Average prediction error: {avg_error:.0f} bikes ({error_percentage:.1f}%)\")\n",
    "\n",
    "if error_percentage < 10:\n",
    "    print(f\"   ‚úÖ Excellent accuracy for operational planning\")\n",
    "elif error_percentage < 20:\n",
    "    print(f\"   ‚úÖ Good accuracy for demand forecasting\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Consider model improvements for better accuracy\")\n",
    "\n",
    "print(f\"\\nüìÅ Generated Files:\")\n",
    "print(f\"   - Training History: ./Section2_Model_Training/ft_transformer_training_history.csv\")\n",
    "print(f\"   - Evaluation Metrics: ./Section2_Model_Training/ft_transformer_evaluation_metrics.csv\")\n",
    "print(f\"   - Predictions: ./Section2_Model_Training/ft_transformer_predictions.csv\")\n",
    "print(f\"   - Model Checkpoint: ./Section2_Model_Training/ft_transformer_model.pth\")\n",
    "print(f\"   - Training Plots: ./Section2_Model_Training/FT_Transformer_training_history.png\")\n",
    "print(f\"   - Evaluation Plots: ./Section2_Model_Training/FT_Transformer_evaluation_results.png\")\n",
    "\n",
    "print(f\"\\nüöÄ FT-Transformer training completed successfully!\")\n",
    "print(f\"   Model ready for deployment and comparison with other models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "\n",
    "1. **Load preprocessed data** from the bike sharing dataset\n",
    "2. **Prepare data** for FT-Transformer training with PyTorch tensors\n",
    "3. **Create an FT-Transformer model** specifically for regression\n",
    "4. **Train the model** with early stopping and learning rate scheduling\n",
    "5. **Evaluate performance** using comprehensive regression metrics\n",
    "6. **Generate visualizations** for training progress and model performance\n",
    "7. **Save all results** for future analysis and comparison\n",
    "\n",
    "The FT-Transformer provides state-of-the-art performance on tabular data by leveraging attention mechanisms to capture complex feature interactions, making it particularly effective for bike sharing demand prediction.\n",
    "\n",
    "### Key Features:\n",
    "- **Modular design**: Each step is implemented as a separate function for flexibility\n",
    "- **Comprehensive evaluation**: Multiple regression metrics and visualizations\n",
    "- **Reproducible results**: Fixed random seeds and saved model checkpoints\n",
    "- **GPU support**: Automatic device detection and memory management\n",
    "- **Early stopping**: Prevents overfitting and saves training time\n",
    "\n",
    "### Next Steps:\n",
    "- Compare with other models (XGBoost, TabPFN, etc.)\n",
    "- Perform hyperparameter tuning\n",
    "- Analyze feature importance and model interpretability\n",
    "- Deploy the model for real-time predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
