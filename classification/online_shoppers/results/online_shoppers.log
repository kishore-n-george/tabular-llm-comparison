2025-07-19 04:23:40,362 - This goes to output.log
2025-07-19 04:23:40,362 - Loading Online Shoppers Dataset...
2025-07-19 04:23:42,558 - Dataset shape: (12330, 18)
2025-07-19 04:23:42,558 - 
Dataset info:
2025-07-19 04:23:42,565 - None
2025-07-19 04:23:42,565 - 
Class distribution:
2025-07-19 04:23:42,565 - Revenue
False    10422
True      1908
Name: count, dtype: int64
2025-07-19 04:23:42,566 - Class imbalance ratio: 5.46:1
2025-07-19 04:23:42,573 - Features shape: (12330, 17)
2025-07-19 04:23:42,573 - Target shape: (12330,)
2025-07-19 04:23:42,573 - Feature names: ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']
2025-07-19 04:23:42,586 - Training set: (7891, 17)
2025-07-19 04:23:42,586 - Validation set: (1973, 17)
2025-07-19 04:23:42,586 - Test set: (2466, 17)
2025-07-19 04:23:42,587 - 
Class distribution in train: [6670 1221]
2025-07-19 04:23:42,587 - Class distribution in val: [1668  305]
2025-07-19 04:23:42,587 - Class distribution in test: [2084  382]
2025-07-19 04:23:42,587 - Training XGBoost...
2025-07-19 04:23:44,881 - Training TabPFN v2...
2025-07-19 04:24:25,220 - Training TabICL...
2025-07-19 04:25:31,389 - Training FT-Transformer...
2025-07-19 04:25:31,389 - FT-Transformer training would be implemented here with proper categorical/numerical feature separation
2025-07-19 04:25:31,389 - For now, we'll skip this model to avoid complexity in the comprehensive comparison
2025-07-19 04:25:32,540 - 
====================================================================================================
2025-07-19 04:25:32,540 - DETAILED PERFORMANCE COMPARISON
2025-07-19 04:25:32,540 - ====================================================================================================
2025-07-19 04:25:32,544 -           model_name  accuracy balanced_accuracy precision    recall        f1       mcc train_time inference_time predictions_per_second   auc_roc avg_precision  log_loss brier_score cv_f1_mean cv_f1_std
XGBoost      XGBoost  0.897405          0.761849  0.712871  0.565445  0.630657  0.577181   0.305111        0.00303          813780.776082   0.92125      0.717805  0.247605     0.07583   0.633772  0.020686
TabPFN v2  TabPFN v2  0.901054          0.774698  0.719745  0.591623  0.649425  0.596322   0.486287       7.841939             314.463025  0.932553      0.753285  0.225356    0.070177   0.667581  0.019888
TabICL        TabICL  0.899432          0.770532  0.714744   0.58377  0.642651  0.588882   0.579337      11.186085             220.452464   0.93395      0.754274  0.222694    0.069713   0.666521  0.024492
2025-07-19 04:25:32,544 - 
============================================================
2025-07-19 04:25:32,544 - EXPLAINABILITY ANALYSIS
2025-07-19 04:25:32,544 - ============================================================
2025-07-19 04:45:32,851 - Using 200 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.
2025-07-19 04:45:38,195 - num_full_subsets = 2
2025-07-19 04:45:38,195 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 04:45:38,195 - num_paired_subset_sizes = 8
2025-07-19 04:45:38,235 - weight_left = 0.5181019626448611
2025-07-19 04:50:29,742 - np.sum(w_aug) = 17.000000000000007
2025-07-19 04:50:29,742 - np.sum(self.kernelWeights) = 1.0000000000000004
2025-07-19 04:50:29,748 - phi = array([-0.00710014,  0.        ,  0.        ,  0.        , -0.00631847,
       -0.00275984,  0.00852667,  0.01507539,  0.10492771,  0.        ,
        0.02129313,  0.        ,  0.        ,  0.00068678,  0.00089538,
        0.00239526,  0.        ])
2025-07-19 04:50:29,749 - np.sum(w_aug) = 17.000000000000007
2025-07-19 04:50:29,750 - np.sum(self.kernelWeights) = 1.0000000000000004
2025-07-19 04:50:29,755 - phi = array([ 0.00710013,  0.        ,  0.        ,  0.        ,  0.00631847,
        0.00275984, -0.00852668, -0.01507539, -0.10492771,  0.        ,
       -0.02129313,  0.        ,  0.        , -0.00068678, -0.00089539,
       -0.00239526,  0.        ])
2025-07-19 04:50:35,118 - num_full_subsets = 2
2025-07-19 04:50:35,118 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 04:50:35,118 - num_paired_subset_sizes = 8
2025-07-19 04:50:35,156 - weight_left = 0.5181019626448611
2025-07-19 04:55:26,909 - np.sum(w_aug) = 17.0
2025-07-19 04:55:26,909 - np.sum(self.kernelWeights) = 1.0
2025-07-19 04:55:26,917 - phi = array([-0.00914353,  0.        ,  0.        ,  0.        , -0.00591318,
       -0.00228299, -0.00784746,  0.00398165,  0.11544423, -0.00125633,
       -0.01308553,  0.        ,  0.        ,  0.        ,  0.00748661,
        0.00209506,  0.        ])
2025-07-19 04:55:26,918 - np.sum(w_aug) = 17.0
2025-07-19 04:55:26,918 - np.sum(self.kernelWeights) = 1.0
2025-07-19 04:55:26,923 - phi = array([ 0.00914352,  0.        ,  0.        ,  0.        ,  0.00591318,
        0.00228298,  0.00784745, -0.00398165, -0.11544423,  0.00125633,
        0.01308553,  0.        ,  0.        ,  0.        , -0.00748661,
       -0.00209506,  0.        ])
2025-07-19 04:55:32,286 - num_full_subsets = 2
2025-07-19 04:55:32,286 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 04:55:32,286 - num_paired_subset_sizes = 8
2025-07-19 04:55:32,325 - weight_left = 0.5181019626448611
2025-07-19 05:00:23,922 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:00:23,922 - np.sum(self.kernelWeights) = 1.0000000000000002
2025-07-19 05:00:23,930 - phi = array([-0.05356938,  0.        ,  0.        ,  0.        , -0.02246538,
       -0.00499614,  0.02482089, -0.00722246, -0.68762453,  0.        ,
        0.        , -0.00248344, -0.00363507,  0.        , -0.01279778,
       -0.04371471,  0.        ])
2025-07-19 05:00:23,931 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:00:23,931 - np.sum(self.kernelWeights) = 1.0000000000000002
2025-07-19 05:00:23,937 - phi = array([ 0.05356938,  0.        ,  0.        ,  0.        ,  0.02246538,
        0.00499614, -0.0248209 ,  0.00722246,  0.68762453,  0.        ,
        0.        ,  0.00248344,  0.00363507,  0.        ,  0.01279778,
        0.04371471,  0.        ])
2025-07-19 05:00:29,302 - num_full_subsets = 2
2025-07-19 05:00:29,303 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 05:00:29,303 - num_paired_subset_sizes = 8
2025-07-19 05:00:29,341 - weight_left = 0.5181019626448611
2025-07-19 05:05:21,176 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:05:21,176 - np.sum(self.kernelWeights) = 1.0000000000000002
2025-07-19 05:05:21,182 - phi = array([-0.00822627,  0.        ,  0.        , -0.00104612, -0.01216054,
       -0.00211046, -0.00592507,  0.01806367,  0.13135111,  0.        ,
        0.01235637,  0.        ,  0.        ,  0.        ,  0.0035009 ,
        0.00182401,  0.        ])
2025-07-19 05:05:21,183 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:05:21,183 - np.sum(self.kernelWeights) = 1.0000000000000002
2025-07-19 05:05:21,189 - phi = array([ 0.00822627,  0.        ,  0.        ,  0.00104612,  0.01216054,
        0.00211046,  0.00592507, -0.01806367, -0.13135111,  0.        ,
       -0.01235638,  0.        ,  0.        ,  0.        , -0.0035009 ,
       -0.00182401,  0.        ])
2025-07-19 05:05:26,553 - num_full_subsets = 2
2025-07-19 05:05:26,553 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 05:05:26,553 - num_paired_subset_sizes = 8
2025-07-19 05:05:26,591 - weight_left = 0.5181019626448611
2025-07-19 05:10:18,135 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:10:18,135 - np.sum(self.kernelWeights) = 1.0
2025-07-19 05:10:18,141 - phi = array([-0.00518489,  0.        ,  0.        , -0.00104345, -0.00664504,
       -0.00188954,  0.00165992,  0.01327347,  0.12037231,  0.        ,
        0.01121594,  0.        ,  0.        ,  0.        , -0.00403714,
        0.00275495,  0.        ])
2025-07-19 05:10:18,142 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:10:18,142 - np.sum(self.kernelWeights) = 1.0
2025-07-19 05:10:18,147 - phi = array([ 0.00518489,  0.        ,  0.        ,  0.00104346,  0.00664505,
        0.00188954, -0.00165992, -0.01327347, -0.1203723 ,  0.        ,
       -0.01121593,  0.        ,  0.        ,  0.        ,  0.00403714,
       -0.00275495,  0.        ])
2025-07-19 05:10:23,510 - num_full_subsets = 2
2025-07-19 05:10:23,510 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 05:10:23,511 - num_paired_subset_sizes = 8
2025-07-19 05:10:23,549 - weight_left = 0.5181019626448611
2025-07-19 05:15:15,118 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:15:15,118 - np.sum(self.kernelWeights) = 1.0000000000000002
2025-07-19 05:15:15,124 - phi = array([-0.00433467,  0.        ,  0.        , -0.00090525,  0.        ,
       -0.00052438,  0.00481212,  0.00057422,  0.11157207,  0.        ,
        0.01802993,  0.        ,  0.00049814,  0.        ,  0.00414323,
        0.00213128,  0.        ])
2025-07-19 05:15:15,125 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:15:15,125 - np.sum(self.kernelWeights) = 1.0000000000000002
2025-07-19 05:15:15,130 - phi = array([ 0.00433467,  0.        ,  0.        ,  0.00090525,  0.        ,
        0.00052438, -0.00481212, -0.00057422, -0.11157207,  0.        ,
       -0.01802994,  0.        , -0.00049814,  0.        , -0.00414323,
       -0.00213128,  0.        ])
2025-07-19 05:15:20,491 - num_full_subsets = 2
2025-07-19 05:15:20,491 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 05:15:20,491 - num_paired_subset_sizes = 8
2025-07-19 05:15:20,529 - weight_left = 0.5181019626448611
2025-07-19 05:20:12,065 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:20:12,065 - np.sum(self.kernelWeights) = 1.0
2025-07-19 05:20:12,071 - phi = array([-0.00734511,  0.        ,  0.        , -0.00075113, -0.01446347,
        0.        ,  0.01194905,  0.01372825,  0.11782637,  0.        ,
        0.00946802,  0.        , -0.00069493,  0.        , -0.00894515,
       -0.01807281,  0.        ])
2025-07-19 05:20:12,072 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:20:12,072 - np.sum(self.kernelWeights) = 1.0
2025-07-19 05:20:12,077 - phi = array([ 0.00734511,  0.        ,  0.        ,  0.00075113,  0.01446348,
        0.        , -0.01194904, -0.01372825, -0.11782636,  0.        ,
       -0.00946802,  0.        ,  0.00069493,  0.        ,  0.00894516,
        0.01807282,  0.        ])
2025-07-19 05:20:17,449 - num_full_subsets = 2
2025-07-19 05:20:17,449 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 05:20:17,449 - num_paired_subset_sizes = 8
2025-07-19 05:20:17,487 - weight_left = 0.5181019626448611
2025-07-19 05:25:09,979 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:25:09,979 - np.sum(self.kernelWeights) = 1.0000000000000002
2025-07-19 05:25:09,985 - phi = array([-0.0084736 ,  0.        , -0.00142912,  0.00767767, -0.02113742,
       -0.00574424, -0.00244997, -0.00771601,  0.10960761,  0.        ,
       -0.06774559,  0.        ,  0.        ,  0.        ,  0.008564  ,
        0.        ,  0.        ])
2025-07-19 05:25:09,986 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:25:09,986 - np.sum(self.kernelWeights) = 1.0000000000000002
2025-07-19 05:25:09,991 - phi = array([ 0.00847359,  0.        ,  0.00142912, -0.00767767,  0.02113741,
        0.00574423,  0.00244997,  0.00771601, -0.10960761,  0.        ,
        0.06774559,  0.        ,  0.        ,  0.        , -0.008564  ,
        0.        ,  0.        ])
2025-07-19 05:25:15,361 - num_full_subsets = 2
2025-07-19 05:25:15,362 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 05:25:15,362 - num_paired_subset_sizes = 8
2025-07-19 05:25:15,400 - weight_left = 0.5181019626448611
2025-07-19 05:30:07,110 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:30:07,110 - np.sum(self.kernelWeights) = 1.0000000000000004
2025-07-19 05:30:07,116 - phi = array([-0.01046378,  0.        ,  0.        , -0.00078039, -0.01747543,
       -0.00116982, -0.00548712, -0.00363853,  0.14139262,  0.        ,
       -0.00934926,  0.        ,  0.        ,  0.        ,  0.00839435,
        0.00148441,  0.        ])
2025-07-19 05:30:07,117 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:30:07,117 - np.sum(self.kernelWeights) = 1.0000000000000004
2025-07-19 05:30:07,122 - phi = array([ 0.01046378,  0.        ,  0.        ,  0.00078039,  0.01747543,
        0.00116982,  0.00548712,  0.00363852, -0.14139262,  0.        ,
        0.00934926,  0.        ,  0.        ,  0.        , -0.00839435,
       -0.00148441,  0.        ])
2025-07-19 05:30:12,485 - num_full_subsets = 2
2025-07-19 05:30:12,485 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 05:30:12,485 - num_paired_subset_sizes = 8
2025-07-19 05:30:12,522 - weight_left = 0.5181019626448611
2025-07-19 05:35:04,001 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:35:04,001 - np.sum(self.kernelWeights) = 1.0000000000000004
2025-07-19 05:35:04,007 - phi = array([-0.00754689,  0.00146188,  0.        , -0.00039219, -0.00929064,
        0.        , -0.00685588,  0.005047  ,  0.13440615,  0.        ,
       -0.01773627,  0.        ,  0.        ,  0.        , -0.01127097,
       -0.01827627,  0.        ])
2025-07-19 05:35:04,008 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:35:04,008 - np.sum(self.kernelWeights) = 1.0000000000000004
2025-07-19 05:35:04,040 - phi = array([ 0.00754689, -0.00146187,  0.        ,  0.00039219,  0.00929064,
        0.        ,  0.00685588, -0.005047  , -0.13440615,  0.        ,
        0.01773628,  0.        ,  0.        ,  0.        ,  0.01127097,
        0.01827627,  0.        ])
2025-07-19 05:35:09,445 - num_full_subsets = 2
2025-07-19 05:35:09,446 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 05:35:09,446 - num_paired_subset_sizes = 8
2025-07-19 05:35:09,492 - weight_left = 0.5181019626448611
2025-07-19 05:40:02,249 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:40:02,249 - np.sum(self.kernelWeights) = 1.0000000000000002
2025-07-19 05:40:02,255 - phi = array([-1.46911425e-02, -3.98413609e-04,  0.00000000e+00, -1.36270891e-03,
       -9.32066794e-03, -7.19483792e-04, -3.66732105e-02, -3.19585486e-02,
       -6.49296869e-01,  0.00000000e+00, -3.47085560e-02,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00, -2.05964655e-02,  0.00000000e+00,
        0.00000000e+00])
2025-07-19 05:40:02,256 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:40:02,256 - np.sum(self.kernelWeights) = 1.0000000000000002
2025-07-19 05:40:02,262 - phi = array([1.46911436e-02, 3.98412341e-04, 0.00000000e+00, 1.36271042e-03,
       9.32066860e-03, 7.19485110e-04, 3.66732110e-02, 3.19585509e-02,
       6.49296868e-01, 0.00000000e+00, 3.47085568e-02, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 2.05964671e-02, 0.00000000e+00,
       0.00000000e+00])
2025-07-19 05:40:07,629 - num_full_subsets = 2
2025-07-19 05:40:07,629 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 05:40:07,629 - num_paired_subset_sizes = 8
2025-07-19 05:40:07,668 - weight_left = 0.5181019626448611
2025-07-19 05:44:59,749 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:44:59,749 - np.sum(self.kernelWeights) = 1.0000000000000002
2025-07-19 05:44:59,755 - phi = array([-0.0170023 ,  0.        ,  0.        , -0.0024461 ,  0.01087143,
        0.        , -0.04257034, -0.06139446, -0.65534999,  0.00277205,
        0.0271664 ,  0.        ,  0.        ,  0.        , -0.0053113 ,
        0.00780501,  0.        ])
2025-07-19 05:44:59,756 - np.sum(w_aug) = 17.000000000000007
2025-07-19 05:44:59,756 - np.sum(self.kernelWeights) = 1.0000000000000002
2025-07-19 05:44:59,762 - phi = array([ 0.01700231,  0.        ,  0.        ,  0.0024461 , -0.01087143,
        0.        ,  0.04257034,  0.06139446,  0.65534999, -0.00277205,
       -0.02716639,  0.        ,  0.        ,  0.        ,  0.0053113 ,
       -0.00780501,  0.        ])
2025-07-19 05:45:05,121 - num_full_subsets = 2
2025-07-19 05:45:05,121 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 05:45:05,122 - num_paired_subset_sizes = 8
2025-07-19 05:45:05,159 - weight_left = 0.5181019626448611
2025-07-19 05:49:58,224 - np.sum(w_aug) = 17.000000000000004
2025-07-19 05:49:58,224 - np.sum(self.kernelWeights) = 1.0000000000000004
2025-07-19 05:49:58,304 - phi = array([-0.00539467, -0.00091098,  0.        ,  0.        , -0.00287188,
        0.        ,  0.00223864,  0.00278448,  0.1057454 ,  0.        ,
        0.03001474,  0.        ,  0.00070886,  0.        ,  0.00226821,
        0.00260468,  0.        ])
2025-07-19 05:49:58,305 - np.sum(w_aug) = 17.000000000000004
2025-07-19 05:49:58,306 - np.sum(self.kernelWeights) = 1.0000000000000004
2025-07-19 05:49:58,427 - phi = array([ 0.00539467,  0.00091098,  0.        ,  0.        ,  0.00287188,
        0.        , -0.00223864, -0.00278447, -0.10574539,  0.        ,
       -0.03001473,  0.        , -0.00070886,  0.        , -0.00226821,
       -0.00260468,  0.        ])
2025-07-19 05:50:03,875 - num_full_subsets = 2
2025-07-19 05:50:03,876 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 05:50:03,876 - num_paired_subset_sizes = 8
2025-07-19 05:50:03,921 - weight_left = 0.5181019626448611
2025-07-19 06:51:08,498 - This goes to output.log
2025-07-19 06:51:08,498 - Loading Online Shoppers Dataset...
2025-07-19 06:51:10,711 - Dataset shape: (12330, 18)
2025-07-19 06:51:10,711 - 
Dataset info:
2025-07-19 06:51:10,717 - None
2025-07-19 06:51:10,717 - 
Class distribution:
2025-07-19 06:51:10,718 - Revenue
False    10422
True      1908
Name: count, dtype: int64
2025-07-19 06:51:10,719 - Class imbalance ratio: 5.46:1
2025-07-19 06:51:10,726 - Features shape: (12330, 17)
2025-07-19 06:51:10,726 - Target shape: (12330,)
2025-07-19 06:51:10,726 - Feature names: ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']
2025-07-19 06:51:10,739 - Training set: (7891, 17)
2025-07-19 06:51:10,739 - Validation set: (1973, 17)
2025-07-19 06:51:10,739 - Test set: (2466, 17)
2025-07-19 06:51:10,739 - 
Class distribution in train: [6670 1221]
2025-07-19 06:51:10,739 - Class distribution in val: [1668  305]
2025-07-19 06:51:10,739 - Class distribution in test: [2084  382]
2025-07-19 06:51:10,739 - Training XGBoost...
2025-07-19 06:51:13,168 - Training TabPFN v2...
2025-07-19 06:54:09,613 - This goes to output.log
2025-07-19 06:54:09,613 - Loading Online Shoppers Dataset...
2025-07-19 06:54:11,556 - Dataset shape: (12330, 18)
2025-07-19 06:54:11,556 - 
Dataset info:
2025-07-19 06:54:11,562 - None
2025-07-19 06:54:11,563 - 
Class distribution:
2025-07-19 06:54:11,563 - Revenue
False    10422
True      1908
Name: count, dtype: int64
2025-07-19 06:54:11,564 - Class imbalance ratio: 5.46:1
2025-07-19 06:54:11,571 - Features shape: (12330, 17)
2025-07-19 06:54:11,571 - Target shape: (12330,)
2025-07-19 06:54:11,571 - Feature names: ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']
2025-07-19 06:54:11,584 - Training set: (7891, 17)
2025-07-19 06:54:11,584 - Validation set: (1973, 17)
2025-07-19 06:54:11,584 - Test set: (2466, 17)
2025-07-19 06:54:11,584 - 
Class distribution in train: [6670 1221]
2025-07-19 06:54:11,584 - Class distribution in val: [1668  305]
2025-07-19 06:54:11,584 - Class distribution in test: [2084  382]
2025-07-19 06:54:11,584 - Training XGBoost...
2025-07-19 06:54:13,902 - Training TabPFN v2...
2025-07-19 06:55:58,868 - This goes to output.log
2025-07-19 06:55:58,868 - Loading Online Shoppers Dataset...
2025-07-19 06:56:01,812 - Dataset shape: (12330, 18)
2025-07-19 06:56:01,812 - 
Dataset info:
2025-07-19 06:56:01,818 - None
2025-07-19 06:56:01,818 - 
Class distribution:
2025-07-19 06:56:01,819 - Revenue
False    10422
True      1908
Name: count, dtype: int64
2025-07-19 06:56:01,820 - Class imbalance ratio: 5.46:1
2025-07-19 06:56:01,827 - Features shape: (12330, 17)
2025-07-19 06:56:01,827 - Target shape: (12330,)
2025-07-19 06:56:01,827 - Feature names: ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']
2025-07-19 06:56:01,840 - Training set: (7891, 17)
2025-07-19 06:56:01,840 - Validation set: (1973, 17)
2025-07-19 06:56:01,840 - Test set: (2466, 17)
2025-07-19 06:56:01,840 - 
Class distribution in train: [6670 1221]
2025-07-19 06:56:01,840 - Class distribution in val: [1668  305]
2025-07-19 06:56:01,840 - Class distribution in test: [2084  382]
2025-07-19 06:56:01,840 - Training XGBoost...
2025-07-19 06:56:07,992 - Training TabPFN v2...
2025-07-19 06:56:48,412 - Training TabICL...
2025-07-19 06:57:54,989 - Training FT-Transformer...
2025-07-19 06:57:54,989 - FT-Transformer training would be implemented here with proper categorical/numerical feature separation
2025-07-19 06:57:54,989 - For now, we'll skip this model to avoid complexity in the comprehensive comparison
2025-07-19 06:57:56,133 - 
====================================================================================================
2025-07-19 06:57:56,133 - DETAILED PERFORMANCE COMPARISON
2025-07-19 06:57:56,133 - ====================================================================================================
2025-07-19 06:57:56,137 -           model_name  accuracy balanced_accuracy precision    recall        f1       mcc train_time inference_time predictions_per_second   auc_roc avg_precision  log_loss brier_score cv_f1_mean cv_f1_std
XGBoost      XGBoost  0.897405          0.761849  0.712871  0.565445  0.630657  0.577181   4.047287       0.003727          661707.738724   0.92125      0.717805  0.247605     0.07583   0.633772  0.020686
TabPFN v2  TabPFN v2  0.901054          0.774698  0.719745  0.591623  0.649425  0.596322   0.492819       7.893831             312.395844  0.932553      0.753285  0.225356    0.070177   0.667581  0.019888
TabICL        TabICL  0.899432          0.770532  0.714744   0.58377  0.642651  0.588882   0.572443      11.247009             219.258288   0.93395      0.754274  0.222694    0.069713   0.666521  0.024492
2025-07-19 06:57:56,137 - 
============================================================
2025-07-19 06:57:56,137 - EXPLAINABILITY ANALYSIS
2025-07-19 06:57:56,137 - ============================================================
2025-07-19 07:18:00,173 - num_full_subsets = 2
2025-07-19 07:18:00,174 - remaining_weight_vector = array([0.23108621, 0.18664656, 0.16176035, 0.14705486, 0.13865173,
       0.13480029])
2025-07-19 07:18:00,174 - num_paired_subset_sizes = 8
2025-07-19 07:18:00,209 - weight_left = 0.5181019626448611
2025-07-19 07:20:08,162 - 
============================================================
2025-07-19 07:20:08,162 - ABLATION STUDIES
2025-07-19 07:20:08,162 - ============================================================
2025-07-19 07:20:41,077 - 
============================================================
2025-07-19 07:20:41,077 - CLASS IMBALANCE ANALYSIS
2025-07-19 07:20:41,077 - ============================================================
2025-07-19 07:20:41,084 - 
XGBoost - Per-Class Performance:
2025-07-19 07:20:41,084 -   Class 0 (No Purchase): Precision=0.9241, Recall=0.9578, F1=0.9406
2025-07-19 07:20:41,084 -   Class 1 (Purchase): Precision=0.7124, Recall=0.5707, F1=0.6337
2025-07-19 07:20:41,086 -   True Negatives: 1996, False Positives: 88
2025-07-19 07:20:41,086 -   False Negatives: 164, True Positives: 218
2025-07-19 07:20:41,086 -   Sensitivity (TPR): 0.5707
2025-07-19 07:20:41,086 -   Specificity (TNR): 0.9578
2025-07-19 07:20:41,086 -   False Positive Rate: 0.0422
2025-07-19 07:20:41,086 -   False Negative Rate: 0.4293
2025-07-19 07:20:47,936 - 
TabPFN v2 - Per-Class Performance:
2025-07-19 07:20:47,936 -   Class 0 (No Purchase): Precision=0.9275, Recall=0.9578, F1=0.9424
2025-07-19 07:20:47,936 -   Class 1 (Purchase): Precision=0.7197, Recall=0.5916, F1=0.6494
2025-07-19 07:20:47,937 -   True Negatives: 1996, False Positives: 88
2025-07-19 07:20:47,937 -   False Negatives: 156, True Positives: 226
2025-07-19 07:20:47,937 -   Sensitivity (TPR): 0.5916
2025-07-19 07:20:47,937 -   Specificity (TNR): 0.9578
2025-07-19 07:20:47,937 -   False Positive Rate: 0.0422
2025-07-19 07:20:47,937 -   False Negative Rate: 0.4084
2025-07-19 07:20:59,251 - 
TabICL - Per-Class Performance:
2025-07-19 07:20:59,251 -   Class 0 (No Purchase): Precision=0.9262, Recall=0.9573, F1=0.9415
2025-07-19 07:20:59,251 -   Class 1 (Purchase): Precision=0.7147, Recall=0.5838, F1=0.6427
2025-07-19 07:20:59,253 -   True Negatives: 1995, False Positives: 89
2025-07-19 07:20:59,253 -   False Negatives: 159, True Positives: 223
2025-07-19 07:20:59,253 -   Sensitivity (TPR): 0.5838
2025-07-19 07:20:59,253 -   Specificity (TNR): 0.9573
2025-07-19 07:20:59,253 -   False Positive Rate: 0.0427
2025-07-19 07:20:59,253 -   False Negative Rate: 0.4162
2025-07-19 07:20:59,253 - 
============================================================
2025-07-19 07:20:59,253 - ERROR ANALYSIS
2025-07-19 07:20:59,253 - ============================================================
2025-07-19 07:20:59,261 - Total misclassified samples: 252 out of 2466
2025-07-19 07:20:59,261 - Misclassification rate: 10.22%
2025-07-19 07:20:59,393 - 
Top 5 features with largest differences in misclassified samples:
2025-07-19 07:20:59,393 -    1. ProductRelated: 0.6927
2025-07-19 07:20:59,393 -    2. Administrative: 0.5914
2025-07-19 07:20:59,393 -    3. ProductRelated_Duration: 0.5894
2025-07-19 07:20:59,394 -    4. PageValues: 0.4513
2025-07-19 07:20:59,394 -    5. Informational: 0.3836
2025-07-19 07:20:59,394 - 
================================================================================
2025-07-19 07:20:59,394 - COMPREHENSIVE ANALYSIS SUMMARY
2025-07-19 07:20:59,394 - ================================================================================
2025-07-19 07:20:59,394 - 
🎯 Key Findings:
2025-07-19 07:20:59,394 - 1. Performance Comparison: [Results from comprehensive evaluation]
2025-07-19 07:20:59,394 - 2. Feature Importance: [Key features identified across models]
2025-07-19 07:20:59,394 - 3. Computational Efficiency: [Training/inference time analysis]
2025-07-19 07:20:59,394 - 4. Class Imbalance Impact: [Minority class performance analysis]
2025-07-19 07:20:59,394 - 5. Error Patterns: [Common misclassification patterns]
2025-07-19 07:20:59,394 - 
📊 Recommendations:
2025-07-19 07:20:59,394 - 1. Best Overall Model: [Based on comprehensive metrics]
2025-07-19 07:20:59,394 - 2. Best for Interpretability: [Most explainable model]
2025-07-19 07:20:59,394 - 3. Best for Speed: [Fastest training/inference]
2025-07-19 07:20:59,394 - 4. Best for Accuracy: [Highest performance model]
2025-07-19 07:20:59,394 - 5. Production Considerations: [Deployment recommendations]
2025-07-19 07:20:59,394 - 
🔬 Future Work:
2025-07-19 07:20:59,394 - 1. Ensemble methods combining best models
2025-07-19 07:20:59,394 - 2. Advanced hyperparameter optimization
2025-07-19 07:20:59,394 - 3. Feature engineering based on importance analysis
2025-07-19 07:20:59,394 - 4. Class balancing techniques
2025-07-19 07:20:59,394 - 5. Model calibration improvements
