{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyM0eUS8spVoYWDYckx5frEa","gpuType":"T4","include_colab_link":true,"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/kishore-n-george/tabular-llm-comparison/blob/main/online_shoppersset_Preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"colab_type":"text","id":"view-in-github"}},{"cell_type":"markdown","source":" %% [markdown]\n# Dry Bean online_shoppersset - online_shoppers Cleansing & Preparation & XGB Classification\n# **Author:** Kishore George\n# **Date:** DD-MM-YYYY  \n# **online_shoppersset Source:** Koklu, M. and Ozkan, I.A. (2020)","metadata":{}},{"cell_type":"code","source":"#!python3 -m venv tabular\n#!source tabular/bin/activate\n!pip install -q numpy pandas scikit-learn shap seaborn matplotlib ucimlrepo xgboost tabpfn lime folium eli5 datasets peft\n# torchvision torchaudio jupyter rtdl\n# ft_transformer\n\n#linear algebra\nimport numpy as np \nimport math\nimport time\n\n#online_shoppers tools\nfrom copy import copy\nimport pandas as pd\nfrom scipy.stats import boxcox\nfrom scipy.special import boxcox1p\nfrom scipy.special import inv_boxcox\nfrom sklearn.preprocessing import PowerTransformer, RobustScaler\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom IPython.display import Image\n\n#plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#models\n\nimport xgboost as xgb\nfrom tabpfn import TabPFNClassifier\n\n#model interpretation modules\nimport lime\nimport lime.lime_tabular\nimport shap\n# import eli5\n\n#metrics\nfrom sklearn.metrics import mean_squared_error, r2_score,accuracy_score,classification_report, confusion_matrix, precision_score, recall_score, f1_score\n\n#awesome interactive map library\nimport folium\nfrom folium.plugins import HeatMap\nfrom folium.plugins import FastMarkerCluster\n\n#statistics\nfrom scipy import stats\n\n#ucimlrepo\nfrom ucimlrepo import fetch_ucirepo, dotdict\n\n%matplotlib inline\nsns.set_style(\"whitegrid\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:08:34.863404Z","iopub.execute_input":"2025-02-13T05:08:34.863775Z","iopub.status.idle":"2025-02-13T05:08:51.470770Z","shell.execute_reply.started":"2025-02-13T05:08:34.863745Z","shell.execute_reply":"2025-02-13T05:08:51.470090Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.5/105.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\n# %% [markdown]\n# ## 2. Load online_shoppersset\nonline_original = fetch_ucirepo(id=468)\nonline_shoppers = online_original.data.original\nprint(\"Dataset shape:\", online_shoppers.shape)\nonline_shoppers.head()\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ZTRN_mxVtv_c","outputId":"ca079274-bd78-4cb3-cb56-3b59c8b3b604","trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:08:55.283181Z","iopub.execute_input":"2025-02-13T05:08:55.283814Z","iopub.status.idle":"2025-02-13T05:08:55.871878Z","shell.execute_reply.started":"2025-02-13T05:08:55.283775Z","shell.execute_reply":"2025-02-13T05:08:55.870980Z"}},"outputs":[{"name":"stdout","text":"Dataset shape: (12330, 18)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Administrative  Administrative_Duration  Informational  \\\n0               0                      0.0              0   \n1               0                      0.0              0   \n2               0                      0.0              0   \n3               0                      0.0              0   \n4               0                      0.0              0   \n\n   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n0                     0.0               1                 0.000000   \n1                     0.0               2                64.000000   \n2                     0.0               1                 0.000000   \n3                     0.0               2                 2.666667   \n4                     0.0              10               627.500000   \n\n   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n0         0.20       0.20         0.0         0.0   Feb                 1   \n1         0.00       0.10         0.0         0.0   Feb                 2   \n2         0.20       0.20         0.0         0.0   Feb                 4   \n3         0.05       0.14         0.0         0.0   Feb                 3   \n4         0.02       0.05         0.0         0.0   Feb                 3   \n\n   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n0        1       1            1  Returning_Visitor    False    False  \n1        2       1            2  Returning_Visitor    False    False  \n2        1       9            3  Returning_Visitor    False    False  \n3        2       2            4  Returning_Visitor    False    False  \n4        3       1            4  Returning_Visitor     True    False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Administrative</th>\n      <th>Administrative_Duration</th>\n      <th>Informational</th>\n      <th>Informational_Duration</th>\n      <th>ProductRelated</th>\n      <th>ProductRelated_Duration</th>\n      <th>BounceRates</th>\n      <th>ExitRates</th>\n      <th>PageValues</th>\n      <th>SpecialDay</th>\n      <th>Month</th>\n      <th>OperatingSystems</th>\n      <th>Browser</th>\n      <th>Region</th>\n      <th>TrafficType</th>\n      <th>VisitorType</th>\n      <th>Weekend</th>\n      <th>Revenue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.20</td>\n      <td>0.20</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Feb</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Returning_Visitor</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>64.000000</td>\n      <td>0.00</td>\n      <td>0.10</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Feb</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Returning_Visitor</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.20</td>\n      <td>0.20</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Feb</td>\n      <td>4</td>\n      <td>1</td>\n      <td>9</td>\n      <td>3</td>\n      <td>Returning_Visitor</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>2.666667</td>\n      <td>0.05</td>\n      <td>0.14</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Feb</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>Returning_Visitor</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>10</td>\n      <td>627.500000</td>\n      <td>0.02</td>\n      <td>0.05</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Feb</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4</td>\n      <td>Returning_Visitor</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"\n# online_shoppers preprocessing\n# Encoding categorical features\nlabel_encoder = LabelEncoder()\nonline_shoppers['Month'] = label_encoder.fit_transform(online_shoppers['Month'])\nonline_shoppers['VisitorType'] = label_encoder.fit_transform(online_shoppers['VisitorType'])\nonline_shoppers['Weekend'] = online_shoppers['Weekend'].astype(int)\n\n# Define features and target variable\nX_shoppers = online_shoppers.drop(columns=['Revenue'])  # Features\ny_shoppers = online_shoppers['Revenue'].astype(int)  # Target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:40:44.197035Z","iopub.execute_input":"2025-02-13T02:40:44.197361Z","iopub.status.idle":"2025-02-13T02:40:44.209019Z","shell.execute_reply.started":"2025-02-13T02:40:44.197334Z","shell.execute_reply":"2025-02-13T02:40:44.208285Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Splitting dataset\nX_train_shoppers, X_test_shoppers, y_train_shoppers, y_test_shoppers = train_test_split(X_shoppers, y_shoppers, test_size=0.2, random_state=42, stratify=y_shoppers)\n\n# Scaling numerical features\nscaler = StandardScaler()\nX_train_shoppers = scaler.fit_transform(X_train_shoppers)\nX_test_shoppers = scaler.transform(X_test_shoppers)\n\n# Model training and evaluation\nxgb_shoppers = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\nstart_time = time.time()\nxgb_shoppers.fit(X_train_shoppers, y_train_shoppers)\nxgb_shoppers_train_time = time.time() - start_time\n\n# XGBoost Predictions\nstart_time = time.time()\nxgb_y_pred_shoppers = xgb_shoppers.predict(X_test_shoppers)\nxgb_shoppers_inference_time = time.time() - start_time\n\n\nprint(f\"XGBoost Training time: {xgb_shoppers_train_time:.4f}\")\nprint(f\"XGBoost Inference time: {xgb_shoppers_inference_time:.4f}\")\n\nacc = accuracy_score(y_test_shoppers, xgb_y_pred_shoppers)\nprint(f\"XGBoost Accuracy: {acc:.4f}\")\nprint(classification_report(y_test_shoppers, xgb_y_pred_shoppers))\n\n# Confusion Matrix\nplt.figure(figsize=(5,4))\nsns.heatmap(confusion_matrix(y_test_shoppers, xgb_y_pred_shoppers), annot=True, fmt='d', cmap='Blues')\nplt.title(\"XGBoost - Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:40:48.257033Z","iopub.execute_input":"2025-02-13T02:40:48.257318Z","iopub.status.idle":"2025-02-13T02:40:48.777245Z","shell.execute_reply.started":"2025-02-13T02:40:48.257296Z","shell.execute_reply":"2025-02-13T02:40:48.776441Z"}},"outputs":[{"name":"stdout","text":"XGBoost Training time: 0.2225\nXGBoost Inference time: 0.0048\nXGBoost Accuracy: 0.9043\n              precision    recall  f1-score   support\n\n           0       0.93      0.96      0.94      2084\n           1       0.73      0.60      0.66       382\n\n    accuracy                           0.90      2466\n   macro avg       0.83      0.78      0.80      2466\nweighted avg       0.90      0.90      0.90      2466\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 500x400 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"TabPFN Implementation","metadata":{}},{"cell_type":"code","source":"# Train TabPFN Classifier\npfn_shoppers_model = TabPFNClassifier(device='cuda')  # Use 'cuda' if GPU is available\nstart_time = time.time()\npfn_shoppers_model.fit(X_train_shoppers, y_train_shoppers)\npfn_train_time = time.time() - start_time\n\n# Predictions\nstart_time = time.time()\ny_pred_shoopers_pfn = pfn_shoppers_model.predict(X_test_shoppers)\npfn_inference_time = time.time() - start_time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:41:01.824722Z","iopub.execute_input":"2025-02-13T02:41:01.825038Z","iopub.status.idle":"2025-02-13T02:41:33.420343Z","shell.execute_reply.started":"2025-02-13T02:41:01.825016Z","shell.execute_reply":"2025-02-13T02:41:33.419333Z"}},"outputs":[{"name":"stderr","text":"Downloading model to /root/.cache/tabpfn/tabpfn-v2-classifier.ckpt.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tabpfn-v2-classifier.ckpt:   0%|          | 0.00/29.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"423c10322c204257aacf4ea3318be2d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/37.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e379cdcfb214f118732a617cecefee7"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"def compute_metrics(y_true, y_pred, model_name):\n    accuracy = accuracy_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred, average='weighted')\n    recall = recall_score(y_true, y_pred, average='weighted')\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    # auc_roc = roc_auc_score(y_true, y_pred,multi_class='ovo')\n    print(f\"{model_name} Performance:\\n Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f} \\n\")\n    #print(f\"{model_name} Performance:\\n Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, AUC-ROC: {auc_roc:.4f}\\n\")\n\n\ncompute_metrics(y_test_shoppers, xgb_y_pred_shoppers, \"XGBoost\")\ncompute_metrics(y_test_shoppers, y_pred_shoopers_pfn, \"TabPFN\")\n\n\n# XGBoost Performance:\n#  Accuracy: 0.9043, Precision: 0.8989, Recall: 0.9043, F1 Score: 0.9004 \n\n# TabPFN Performance:\n# Accuracy: 0.9023, Precision: 0.8977, Recall: 0.9023, F1 Score: 0.8994 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:41:33.446342Z","iopub.execute_input":"2025-02-13T02:41:33.446643Z","iopub.status.idle":"2025-02-13T02:41:33.470047Z","shell.execute_reply.started":"2025-02-13T02:41:33.446623Z","shell.execute_reply":"2025-02-13T02:41:33.469332Z"}},"outputs":[{"name":"stdout","text":"XGBoost Performance:\n Accuracy: 0.9043, Precision: 0.8989, Recall: 0.9043, F1 Score: 0.9004 \n\nTabPFN Performance:\n Accuracy: 0.9023, Precision: 0.8977, Recall: 0.9023, F1 Score: 0.8994 \n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Table LLM","metadata":{}},{"cell_type":"code","source":"# # Load model directly\n# from transformers import AutoTokenizer, AutoModelForCausalLM\n\n# tokenizer = AutoTokenizer.from_pretrained(\"RUCKBReasoning/TableLLM-13b\")\n# tablellm_model = AutoModelForCausalLM.from_pretrained(\"RUCKBReasoning/TableLLM-13b\")\n\n# Load model directly\n# from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n# import torch\n\n\n# tokenizer = AutoTokenizer.from_pretrained(\"RUCKBReasoning/TableLLM-7b\")\n# # Enable 4-bit quantization\n# bnb_config = BitsAndBytesConfig(\n#     load_in_4bit=True,  # Use 4-bit quantization\n#     bnb_4bit_compute_dtype=torch.float16,\n#     bnb_4bit_use_double_quant=True,\n# )\n\n# model = AutoModelForCausalLM.from_pretrained(\"RUCKBReasoning/TableLLM-7b\",quantization_config=bnb_config, device_map=\"auto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:41:38.457890Z","iopub.execute_input":"2025-02-13T02:41:38.458180Z","iopub.status.idle":"2025-02-13T02:41:38.461913Z","shell.execute_reply.started":"2025-02-13T02:41:38.458159Z","shell.execute_reply":"2025-02-13T02:41:38.460890Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"## resetting to base data, removing onehot encoding\nonline_original = fetch_ucirepo(id=468)\nonline_shoppers = online_original.data.original\n# Define features and target variable\n#X_shoppers = online_shoppers.drop(columns=['Revenue'])  # Features\n#y_shoppers = online_shoppers['Revenue'].astype(int)  # Target\n#X_train_shoppers, X_test_shoppers, y_train_shoppers, y_test_shoppers = train_test_split(X_shoppers, y_shoppers, test_size=0.2, random_state=42, stratify=y_shoppers)\n\nfrom datasets import Dataset\n\ndef convert_to_table_prompt(df_row):\n    \"\"\"Format the tabular row into a natural language prompt for TableLLM\"\"\"\n    prompt = f\"Given the following online shopper session details, predict whether the user will make a purchase (1) or not (0):\\n\\n\"\n    prompt += \"\\n\".join([f\"{col}: {val}\" for col, val in df_row.items()])\n    prompt += \"\\n\\nPrediction:\"\n    return prompt\n\n# Apply transformation\nonline_shoppers[\"Revenue\"] = online_shoppers[\"Revenue\"].astype(int)\n# print(\"Unique labels:\", np.unique(online_shoppers[\"Revenue\"]))  # Should be [0, 1]\n# print(online_shoppers[\"Revenue\"].isna().sum())\n\n# online_shoppers[\"Revenue\"] = online_shoppers[\"Revenue\"].astype(str)\nonline_shoppers[\"prompt\"] = online_shoppers.drop(columns=[\"Revenue\"]).apply(convert_to_table_prompt, axis=1)\n\n\n# Convert dataset to Hugging Face `Dataset` format\nhf_dataset = Dataset.from_pandas(online_shoppers[[\"prompt\", \"Revenue\"]])\nhf_dataset = hf_dataset.rename_columns({\"Revenue\": \"labels\"})\n\nprint(hf_dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:09:22.762393Z","iopub.execute_input":"2025-02-13T05:09:22.762754Z","iopub.status.idle":"2025-02-13T05:09:24.944225Z","shell.execute_reply.started":"2025-02-13T05:09:22.762716Z","shell.execute_reply":"2025-02-13T05:09:24.943450Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['prompt', 'labels'],\n    num_rows: 12330\n})\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(hf_dataset[65])\n#print(online_shoppers.loc[online_shoppers['Revenue'] == True])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:09:25.854153Z","iopub.execute_input":"2025-02-13T05:09:25.854790Z","iopub.status.idle":"2025-02-13T05:09:25.861123Z","shell.execute_reply.started":"2025-02-13T05:09:25.854751Z","shell.execute_reply":"2025-02-13T05:09:25.860195Z"}},"outputs":[{"name":"stdout","text":"{'prompt': 'Given the following online shopper session details, predict whether the user will make a purchase (1) or not (0):\\n\\nAdministrative: 3\\nAdministrative_Duration: 87.83333333\\nInformational: 0\\nInformational_Duration: 0.0\\nProductRelated: 27\\nProductRelated_Duration: 798.3333333\\nBounceRates: 0.0\\nExitRates: 0.012643678\\nPageValues: 22.9160357\\nSpecialDay: 0.8\\nMonth: Feb\\nOperatingSystems: 2\\nBrowser: 2\\nRegion: 3\\nTrafficType: 1\\nVisitorType: Returning_Visitor\\nWeekend: False\\n\\nPrediction:', 'labels': 1}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Fine Tune Table LLM","metadata":{}},{"cell_type":"code","source":"import os\n# disable Weights and Biases\nos.environ['WANDB_DISABLED']=\"true\"\nos.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\nos.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:09:28.230176Z","iopub.execute_input":"2025-02-13T05:09:28.230485Z","iopub.status.idle":"2025-02-13T05:09:28.234563Z","shell.execute_reply.started":"2025-02-13T05:09:28.230459Z","shell.execute_reply":"2025-02-13T05:09:28.233696Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!pip show bitsandbytes\n!pip install -U bitsandbytes\n!pip uninstall transformers accelerate --yes\n!pip install --upgrade transformers accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:09:30.821910Z","iopub.execute_input":"2025-02-13T05:09:30.822212Z","iopub.status.idle":"2025-02-13T05:09:49.358011Z","shell.execute_reply.started":"2025-02-13T05:09:30.822190Z","shell.execute_reply":"2025-02-13T05:09:49.357138Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Package(s) not found: bitsandbytes\u001b[0m\u001b[33m\n\u001b[0mCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.2\nFound existing installation: transformers 4.47.0\nUninstalling transformers-4.47.0:\n  Successfully uninstalled transformers-4.47.0\nFound existing installation: accelerate 1.2.1\nUninstalling accelerate-1.2.1:\n  Successfully uninstalled accelerate-1.2.1\nCollecting transformers\n  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate\n  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.28.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.6/336.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: transformers, accelerate\nSuccessfully installed accelerate-1.3.0 transformers-4.48.3\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq, AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\nimport torch\nimport bitsandbytes as bnb\nimport transformers as tf\nprint(\"bitsandbytes version:\", bnb.__version__)  # Ensure it is correctly installed\nprint(\"tf version:\", tf.__version__)  \ncompute_dtype = getattr(torch, \"float16\")\nprint(compute_dtype)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:09:53.935632Z","iopub.execute_input":"2025-02-13T05:09:53.935971Z","iopub.status.idle":"2025-02-13T05:10:10.153435Z","shell.execute_reply.started":"2025-02-13T05:09:53.935946Z","shell.execute_reply":"2025-02-13T05:10:10.152746Z"}},"outputs":[{"name":"stdout","text":"bitsandbytes version: 0.45.2\ntf version: 4.48.3\ntorch.float16\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:10:12.035700Z","iopub.execute_input":"2025-02-13T05:10:12.036451Z","iopub.status.idle":"2025-02-13T05:10:12.041466Z","shell.execute_reply.started":"2025-02-13T05:10:12.036423Z","shell.execute_reply":"2025-02-13T05:10:12.040568Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"model_name = \"RUCKBReasoning/TableLLM-7b\"\n\n# model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\", offload_folder=\"offload\",)\n\nbnb_config_gpu = BitsAndBytesConfig(\n                load_in_4bit=True, \n                bnb_4bit_quant_type='nf4',\n                bnb_4bit_compute_dtype=compute_dtype,\n                bnb_4bit_use_double_quant=False, \n                llm_int8_enable_fp32_cpu_offload=True )\n\nbnb_config_cpu = BitsAndBytesConfig(\n    load_in_4bit=False,  # Disable quantization\n    bnb_4bit_compute_dtype=torch.float32,  # Use float32 for CPU training\n    llm_int8_enable_fp32_cpu_offload=True\n)\n\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    # quantization_config=bnb_config_cpu,\n    # device_map={\"\": torch.cuda.current_device()} if device == \"cuda\" else {\"\": \"cpu\"}, # for gpu\n    device_map={\"\": \"cpu\"},\n    # torch_dtype=torch.float16, # for gpu\n    torch_dtype=torch.float32,\n    offload_folder=\"offload\"\n)\n# ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:22:43.788141Z","iopub.execute_input":"2025-02-13T05:22:43.788528Z","execution_failed":"2025-02-13T06:06:52.279Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1733d05d79347bca3c7f4629db2d66f"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"#!pip install bitsandbytes\n# !pip uninstall bitsandbytes --yes\nprint(f\"Tokenizer vocabulary size: {len(tokenizer)}\")\nprint(f\"Model vocabulary size: {model.config.vocab_size}\")\n\nif len(tokenizer) == model.config.vocab_size:\n    print(\"Tokenizer and model vocabulary sizes match.\")\nelse:\n    print(\"Warning: Tokenizer and model vocabulary sizes do NOT match!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:16:16.032193Z","iopub.execute_input":"2025-02-13T05:16:16.032504Z","iopub.status.idle":"2025-02-13T05:16:16.049856Z","shell.execute_reply.started":"2025-02-13T05:16:16.032478Z","shell.execute_reply":"2025-02-13T05:16:16.048972Z"}},"outputs":[{"name":"stdout","text":"Tokenizer vocabulary size: 32017\nModel vocabulary size: 32016\nWarning: Tokenizer and model vocabulary sizes do NOT match!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"text = \"TableLLM fine-tuning test\"\ntokens = tokenizer(text, return_tensors=\"pt\")\n\n# Print tokenized input\nprint(\"Tokens:\", tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"].squeeze().tolist()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T03:19:23.793398Z","iopub.execute_input":"2025-02-13T03:19:23.793732Z","iopub.status.idle":"2025-02-13T03:19:23.801476Z","shell.execute_reply.started":"2025-02-13T03:19:23.793706Z","shell.execute_reply":"2025-02-13T03:19:23.800747Z"}},"outputs":[{"name":"stdout","text":"Tokens: ['<s>', '▁Table', 'LL', 'M', '▁fine', '-', 't', 'uning', '▁test']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(tokenizer.special_tokens_map)\nprint(tokenizer.additional_special_tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T03:21:17.773147Z","iopub.execute_input":"2025-02-13T03:21:17.773512Z","iopub.status.idle":"2025-02-13T03:21:17.778299Z","shell.execute_reply.started":"2025-02-13T03:21:17.773490Z","shell.execute_reply":"2025-02-13T03:21:17.777391Z"}},"outputs":[{"name":"stdout","text":"{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}\n[]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model.resize_token_embeddings(len(tokenizer))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:16:20.221284Z","iopub.execute_input":"2025-02-13T05:16:20.221761Z","iopub.status.idle":"2025-02-13T05:17:09.001819Z","shell.execute_reply.started":"2025-02-13T05:16:20.221717Z","shell.execute_reply":"2025-02-13T05:17:09.000944Z"}},"outputs":[{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\nThe new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Embedding(32017, 4096)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"print(f\"Updated Tokenizer Vocab Size: {len(tokenizer)}\")\nprint(f\"Updated Model Vocab Size: {model.config.vocab_size}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:18:11.401090Z","iopub.execute_input":"2025-02-13T05:18:11.401422Z","iopub.status.idle":"2025-02-13T05:18:11.412386Z","shell.execute_reply.started":"2025-02-13T05:18:11.401399Z","shell.execute_reply":"2025-02-13T05:18:11.411497Z"}},"outputs":[{"name":"stdout","text":"Updated Tokenizer Vocab Size: 32017\nUpdated Model Vocab Size: 32017\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\n# Define LoRA Configuration\nlora_config = LoraConfig(\n    r=8,  # Rank of the LoRA update matrices\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"v_proj\"],  # Apply LoRA only to attention layers\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"  # AutoModelForCausalLM is a causal language model\n)\n\n# Attach LoRA adapters\npeft_model = get_peft_model(model, lora_config)\npeft_model.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:18:13.440074Z","iopub.execute_input":"2025-02-13T05:18:13.440402Z","iopub.status.idle":"2025-02-13T05:18:13.584789Z","shell.execute_reply.started":"2025-02-13T05:18:13.440374Z","shell.execute_reply":"2025-02-13T05:18:13.583872Z"}},"outputs":[{"name":"stdout","text":"trainable params: 4,194,304 || all params: 26,170,765,312 || trainable%: 0.0160\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(f\"Updated Model Vocab Size: {peft_model.config.vocab_size}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:18:17.547348Z","iopub.execute_input":"2025-02-13T05:18:17.547742Z","iopub.status.idle":"2025-02-13T05:18:17.552431Z","shell.execute_reply.started":"2025-02-13T05:18:17.547710Z","shell.execute_reply":"2025-02-13T05:18:17.551691Z"}},"outputs":[{"name":"stdout","text":"Updated Model Vocab Size: 32017\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"device = torch.device(\"cpu\")  # Use \"cuda\" if using GPU\nprint(device)\npeft_model.to(device)  # Move model to CPU\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:18:22.733218Z","iopub.execute_input":"2025-02-13T05:18:22.733540Z","iopub.status.idle":"2025-02-13T05:18:22.757423Z","shell.execute_reply.started":"2025-02-13T05:18:22.733515Z","shell.execute_reply":"2025-02-13T05:18:22.756699Z"}},"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(32017, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=32017, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# Tokenize dataset\nprint(device)\ndef preprocess_function(examples):\n    model_inputs = tokenizer(examples[\"prompt\"], padding=\"longest\", truncation=True) #changing padding to longest for cuda error\n    model_inputs[\"labels\"] = examples[\"labels\"]\n    # model_inputs[\"labels\"] = tokenizer(examples[\"labels\"], truncation=True)[\"input_ids\"] # avoid padding here for cuda error padding=\"max_length\"\n        # Move tensors to the same device as the model\n    # model_inputs = {key: torch.tensor(val).to(device) for key, val in model_inputs.items()} # needed for GPU\n    \n    return model_inputs\n    # model_inputs[\"labels\"] = examples[\"labels\"]\n\n\ntokenized_dataset = hf_dataset.map(preprocess_function, batched=True)\n\n# Data collator for training\n# data_collator = DataCollatorForSeq2Seq(tokenizer, model=peft_model)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:18:27.543044Z","iopub.execute_input":"2025-02-13T05:18:27.543381Z","iopub.status.idle":"2025-02-13T05:18:30.117424Z","shell.execute_reply.started":"2025-02-13T05:18:27.543354Z","shell.execute_reply":"2025-02-13T05:18:30.116515Z"}},"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12330 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1afd80d5ecc843e78dbe64b82066279d"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"for name, param in peft_model.named_parameters():\n    if param.requires_grad:\n        print(name, param.shape)  # Should print only LoRA parameters\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:18:40.818533Z","iopub.execute_input":"2025-02-13T05:18:40.818895Z","iopub.status.idle":"2025-02-13T05:18:40.857118Z","shell.execute_reply.started":"2025-02-13T05:18:40.818868Z","shell.execute_reply":"2025-02-13T05:18:40.856418Z"}},"outputs":[{"name":"stdout","text":"base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight torch.Size([4096, 8])\nbase_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight torch.Size([8, 4096])\nbase_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight torch.Size([4096, 8])\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n# !export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n\n# torch.cuda.empty_cache()\n\n# Assuming 'peft_model' is your model\n\n# peft_model.to_empty(device='cpu')  # If the model is in a meta state, use this\n\n# Move the model to the desired device (cuda, cpu)\n# peft_model.to('cpu')  # Move the model to the target device\n\n# tokenized_dataset.to('cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:18:44.295048Z","iopub.execute_input":"2025-02-13T05:18:44.295338Z","iopub.status.idle":"2025-02-13T05:18:44.299383Z","shell.execute_reply.started":"2025-02-13T05:18:44.295315Z","shell.execute_reply":"2025-02-13T05:18:44.298498Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n\ntraining_args = TrainingArguments(\n    output_dir=\"./fine_tuned_tablellm\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-4,  # Use a slightly higher learning rate for LoRA\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    fp16=True if torch.cuda.is_available() else False, # changing to false to avoid cuda error\n    push_to_hub=False,\n    gradient_accumulation_steps=4\n)\n\ntrainer = Trainer(\n    model=peft_model,\n    args=training_args,\n    train_dataset=tokenized_dataset,  # Make sure dataset is properly tokenized\n    eval_dataset=tokenized_dataset,\n    tokenizer=tokenizer\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:18:53.844342Z","iopub.execute_input":"2025-02-13T05:18:53.844696Z","iopub.status.idle":"2025-02-13T05:18:54.167448Z","shell.execute_reply.started":"2025-02-13T05:18:53.844670Z","shell.execute_reply":"2025-02-13T05:18:54.166811Z"}},"outputs":[{"name":"stderr","text":"`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"  # Debugging flag\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T05:19:02.541466Z","iopub.execute_input":"2025-02-13T05:19:02.541832Z","iopub.status.idle":"2025-02-13T05:19:03.241823Z","shell.execute_reply.started":"2025-02-13T05:19:02.541804Z","shell.execute_reply":"2025-02-13T05:19:03.240660Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-e1ae560f0841>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Debugging flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2171\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2172\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2328\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2330\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2332\u001b[0m                 \u001b[0;31m# to handle cases wherein we pass \"DummyScheduler\" such as when it is specified in DeepSpeed config.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, device_placement, *args)\u001b[0m\n\u001b[1;32m   1337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp8_backend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"MSAMP\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_msamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_placement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m             result = tuple(\n\u001b[0m\u001b[1;32m   1340\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_pass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_msamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_placement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m             result = tuple(\n\u001b[0;32m-> 1340\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_pass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m             )\n\u001b[1;32m   1342\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36m_prepare_one\u001b[0;34m(self, obj, first_pass, device_placement)\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_placement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_placement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m                 \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_placement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mprepare_model\u001b[0;34m(self, model, device_placement, evaluation_mode)\u001b[0m\n\u001b[1;32m   1439\u001b[0m                     \u001b[0;31m# if on the first device (GPU 0) we don't care\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent_device_index\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m   1442\u001b[0m                             \u001b[0;34m\"You can't train a model that has been loaded in 8-bit or 4-bit precision on a different device than the one \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m                             \u001b[0;34m\"you're training on. Make sure you loaded the model on the correct device using for example `device_map={'':torch.cuda.current_device()}` or `device_map={'':torch.xpu.current_device()}`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: You can't train a model that has been loaded in 8-bit or 4-bit precision on a different device than the one you're training on. Make sure you loaded the model on the correct device using for example `device_map={'':torch.cuda.current_device()}` or `device_map={'':torch.xpu.current_device()}`"],"ename":"ValueError","evalue":"You can't train a model that has been loaded in 8-bit or 4-bit precision on a different device than the one you're training on. Make sure you loaded the model on the correct device using for example `device_map={'':torch.cuda.current_device()}` or `device_map={'':torch.xpu.current_device()}`","output_type":"error"}],"execution_count":20},{"cell_type":"code","source":"#Saving fine-tuned model\ntrainer.save_model(\"./fine_tuned_tablellm\")\ntokenizer.save_pretrained(\"./fine_tuned_tablellm\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T05:42:28.885095Z","iopub.status.idle":"2025-02-12T05:42:28.885460Z","shell.execute_reply":"2025-02-12T05:42:28.885300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n# Convert tabular data to text format for Table LLM\ndef convert_to_table_prompt(df_row):\n    prompt = f\"Given the following online shopper session details, predict whether the user will make a purchase (1) or not (0):\\n\\n\"\n    prompt += \"\\n\".join([f\"{col}: {val}\" for col, val in df_row.items()])\n    prompt += \"\\n\\nPrediction:\"\n    return prompt\n\n\nfeatures = online_shoppers.drop(columns=[\"Revenue\"])\n\nX_test_shoppers = pd.DataFrame(X_test_shoppers, columns=features.columns) \nX_test_text = X_test_shoppers.apply(convert_to_table_prompt, axis=1).tolist()\n\nprint(X_test_text)\nX_test_text_sampled = X_test_text[:10]\ny_test_sampled = y_test_shoppers[:10]\nprint(X_test_text_sampled)\nprint(y_test_sampled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T05:42:28.886341Z","iopub.status.idle":"2025-02-12T05:42:28.886642Z","shell.execute_reply":"2025-02-12T05:42:28.886483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tokenize and generate predictions\nimport re\ny_pred_tablellm = []\nfor text in X_test_text_sampled:\n# text = \"Given the following online shopper session details, predict whether the user will make a purchase (1) or not (0).:\\n\\nAdministrative: 1\\nAdministrative_Duration: 4.0\\nInformational: 0\\nInformational_Duration: 0.0\\nProductRelated: 13\\nProductRelated_Duration: 161.1666667\\nBounceRates: 0.024615385\\nExitRates: 0.061538462\\nPageValues: 0.0\\nSpecialDay: 0.6\\nMonth: May\\nOperatingSystems: 2\\nBrowser: 5\\nRegion: 9\\nTrafficType: 5\\nVisitorType: Returning_Visitor\\nWeekend: False\\n\\nPrediction:\"\n    inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n    with torch.no_grad():\n        outputs = model.generate(**inputs, max_new_tokens=256)\n    y_preds = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    print(y_preds)\n    # Regular expression to match the 'Prediction' key and extract its value\n    match = re.search(r'Prediction:\\s*(\\d+)', y_preds)\n\n    if match:\n        prediction_value = match.group(1)\n        print(prediction_value)\n        y_pred_tablellm.append(prediction_value)\n    else:\n        print(\"Prediction key not found\")\n        y_pred_tablellm.append(-1)\n\n\n# Evaluate Performance\naccuracy = accuracy_score(y_test_sampled, y_pred_tablellm)\n# print(f\"TableLLM 13B Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T05:42:28.887443Z","iopub.status.idle":"2025-02-12T05:42:28.887785Z","shell.execute_reply":"2025-02-12T05:42:28.887678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(accuracy)\nprint(y_pred_tablellm)\nprint(y_test_sampled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T05:42:28.888397Z","iopub.status.idle":"2025-02-12T05:42:28.888716Z","shell.execute_reply":"2025-02-12T05:42:28.888565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}